http协议
    -概念:服务器与客户端进行数据交互的一种形式
    -是不加密的
常用请求头信息
    -User-Agent:请求载体的身份信息
    -Connection:请求完毕后，是断开连接还是保持连接
常用响应头信息
    -Connect-Type:服务器端响应回客户端的数据类型
https协议:
    -安全的超文本传输协议
    -加密的
加密方式
    -对称密钥加密
    -非对称密钥加密
    -证书密钥加密

requests模块
    -urllib模块--->较古老
    -requests模块--->较推荐
python中原生的一款基于网络请求的模块，功能强大，效率高
作用:模拟浏览器发请求
如何使用: (requests模块的编码流程)
    -指定url
    -发起请求
        ua--->请求载体的身份标识
        ua检测：门户网站的服务器会检测对应请求的载体任务表示，如果家安测到请求的载体身份标识为某款浏览器，则说明该请求是一个正常的请求。如果检测到的身份标识不属于某款浏览器，则表示该请求为不正常的请求(爬虫)，服务器有可能会拒绝该次请求
        ua伪装:让爬虫对应的请求载体身份标识伪装成某一款浏览器
    -获取响应数据
    -持久化存储(即将数据写入到硬盘中而非内存)

编码流程：
    -指定url
    -发起请求
    -获取响应数据
    -数据解析
    -持久化储存
数据解析分类:
    -正则表达式
    -bs4
    -xpath --->通用性较强
数据解析原理概述:
    -解析的局部内容的文本内容都会在标签之间或者标签对应的属性中进行储存
    -1.进行指定标签的定位
    -2.标签或者标签对应的属性中储存的数据值进行提取(解析)

bs4进行数据解析
    -数据解析的原理
        -1.标签定位
        -2.提取标签，标签属性或者标签对应的属性中存储的数据值
    -bs4数据解析的原理
        -1.实例化一个BeautifulSoup对象，并且将页面源码数据加载到该对象中
        -2.通过调用BeautifulSoup对象中相关的属性或者方法进行标签定位和数据提取
    -对象的实例化:
        -1.将本地的html文档中的数据加载到该对象中
        soup = bs4.BeautifulSoup(fp,'lxml')
        -2.将互联网上获取的页面源码加载到该对象中
    -提供的用于数据解析的方法和属性:
        -soup.tagName--->返回文档中第一次出现的tagName标签
        -soup.find():
            find('tagName')--->等同于soup.div
        -属性定位
            -soup.find('div',class_/id/attr='  ')
            -soup.find_all('tagName')--->以列表形式返回所有符合条件的标签
        -select:
            -select('某种选择器(id,class,标签...选择器)')--->返回的是一个列表
            -层级选择器:
                select('.   >   >   >   ')--->每个>空出来的位置都表示一个层级,空格则表示该层级下所有的某个集
        -获取标签之间的文本数据:
            -soup.a.text/string/get_text()
            -text/get_text()可以获取某一个标签中所有的文本内容
            -string:只可以获取该标签下面直系的文本内容
        -获取标签中属性值:
            -soup.a['href']
    -xpath解析原理:
        -1.实例化一个etree的对象，且需要将被解析的页面源码数据1加载到该对象中。
        -2.调用etree对象中的xpath方法结合着xpath表达式实现标签的定位和内容的捕获
    -如何实例化一个e'tree对象
        -1.将本地的html文档中的源码数据加载到etree对象中:
            paris = etree.parse(文件路径,etree.HTMLParser(encoding='utf-8'))
        -2.将互联网上的源码数据加载到该对象中
            etree.HTML('page_text')
    -xpath('xpath表达式')
        -1./代表从根节点开始定位。表示的是一个层级。
        -2.//表示多个层级，可以表示从任意位置开始定位。
        -属性定位://div[@class='属性的名称']     tag[@attrName="attrValue"]
        -索引定位://div[@class=" "]/p[3]  --->后面选择的是输出p标签下第几个内容(索引是从1开始的)
        -取文本:
            -/text() 获取标签中的直系内容
            -//text() 获取标签下的全部内容
        -取属性:
            /@attrName   ==>img/src
        normalize-space()可以去掉xpath找出来的\t \r \n这些东西


验证码识别
反爬机制:验证码，识别验证码图片中的数据，用于模拟操作
识别验证码的操作:
    -1.人工肉眼识别(不推荐)
    -2.第三方自动识别(推荐)


模拟登录:
    模拟用户登录
    -登录以后服务器会给一个cookie
    -再带着cookie去请求url->对应的内容
    -这两个操作必须连起来
    -可以使用session进行请求 ->在session中cookie不会丢失